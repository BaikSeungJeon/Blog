# 지도학습

지도 학습은 데이터 -> 입력 -> 실행(학습) -> 모델(수식) -> 예측의 플로우를 가지고 있습니다. 여기서 데이터는 또 학습 데이터 : 레이블의 구조를 가지고 있습니다. 레이블은 단변량입니다.

데이터를 입력하고 예측한 결과가 나오는데, 예측값이 연속적인 숫자면 <code>Regression</code> 모델이라 하고, 예측값이 이산적인 숫자 즉 분류값이 나오면 <code>Classification</code> 모델이라고 합니다. 참고로 여기서 말하는 <code>Regression</code>은 앞에서 말한 통계 학습을 의미하는 <code>Regression</code>과 다릅니다.

## Regression(회귀)
> 어떤 데이터에 대해, 그 데이터에 영향을 주는 조건들의 영향력을 이용해서, 데이터에 대한 조건부 평균을 구하는 기법

"우리나라의 아파트 가격은 얼마인가요?"라는 물음과, '1억'이라는 평균에 대해 누군가는 "1억이냐 하냐"와, "1억밖에 안 하냐"는 의견이 분분할 것입니다. 즉 이런 데이터는 '연도별 아파트 가격 추이'와 같은 자료에는 적합한 자료일지 몰라도 개개인의 입장에서 봤을 때 이처럼 구하는 것은 그닥 큰 도움은 안 될 것입니다.

아파트 가격에 가장 큰 영향을 주는 조건들이 무엇이 있을까요? 아마 '평수', '지역', '학군' 등이 있을 것입니다. 이러한 조건들을 사용해 수식을 한 번 만들어 보겠습니다.

<pre>
가격 =      평수      +       역세권    +     학군
y   = (평수 * 8000)  + (역세권 * 3000) + (학군 * 5000)
</pre>

회귀 분석이란 이러한 수식을 만드는 것을 의미합니다. 회귀 분석 모델을 만들고, 저희가 모델을 만드는 이유가 예측하기 위함인 것처럼, 모델이 존재하니 예측이 가능해졌습니다.

한마디로 Regression은 평균을 구하는 겁니다. 평균은 우리가 대푯값으로 가장 많이 이용하는 값입니다. 즉 어떤 데이터에 대해 가장 잘 표현하는 값인데, 여러가지 값이 있기 때문에 함수 형태로 표현이 됩니다.

## Regression Model

키, 몸무게, BMI 지수가 있습니다. 여기서 키와 몸무게는 독립 변수이고, BMI 지수는 종속 변수입니다. BMI 지수를 구하려면 키와 몸무게가 필요하며, 이 둘에 영향을 받고 있기 때문입니다.

비슷한 관계로 연수 기간과 공부 시간, 성적이란 변수가 있다고 가정했을 때, 이때도 연수 기간과 공부 시간에 의해 성적이 결정될 테니, 연수 기간과 공부 시간은 독립 변수이고, 성적은 종속 변수가 될 것입니다.

이를 Regression 기법에서 비추어 보면, 독립 변수인 연수 기간과 공부 시간은 다른 말로 특성(<code>feature</code>), 성적은 <code>target</code>이라고 합니다. 그리고 앞서 말했단 데이터 안에 데이터 : 레이블 구조와 매핑해 보면, 특성은 X-데이터, 타겟은 레이블이 됩니다.

종속 변수가 1개인 걸 가정했을 때, 만약 독립 변수가 1개라면 수식은 다음과 같습니다.

<pre>
예측치 = 가중치 x + 상수
y    =   β0x   + β1
</pre>

여기서 β를 보기 쉽게 기호를 바꿔 다시 작성해 보겠습니다.

<pre>
예측치 = 가중치 x + 상수
y    =   ax    +  b
</pre>

이 수식은 일차함수와 같은 식을 띠는 것을 볼 수 있습니다. 결론적으로 독립 변수가 한 개인 경우는 일차함수와 같은 것을 알 수 있습니다. 상상을 조금 더 곁들인다면, 독립 변수가 두 개라면 2차원, 독립 변수가 세 개라면 3차원으로 그려질 겁니다.

다시 돌아와서, <code>y = ax + b</code> 형태로 만들어진 걸 우리는 <code>Classical Linear Regression Model</code>이라고 합니다. 

독립 변수가 두 개일 때 식은 <code>y = ax1 + bx2 + c</code>와 같이 되고, 그림은 평면의 형태를 갖게 됩니다. 여기서 독립 변수가 1개일 때 <code>a</code>와 <code>b</code>만 구하면 되지만, 독립 변수가 2개인 경우 <code>a</code>와 <code>b</code>, <code>c</code>까지 구해야 합니다. 여기서 저 <code>a, b, c</code>를 회기계수라 합니다.

<code>Regression</code>은 평균에 많이 의지하고 있어, 만약 데이터가 평균을 사용하기 힘든 데이터라면 회귀모델 사용을 고려해봐야 합니다. 성인 남성의 키의 경우 약 170몇처럼 평균이 특정 데이터를 대표하는 것과 다르게, 월급처럼 저소득층이 많고, 고소득층이 적은 데이터의 경우 그래프가 한쪽으로 치우쳐져 있습니다. 이렇게 편향된 경우 데이터를 가공하거나 회기모델 사용을 고려해야 하는 것입니다.

### Loss Function(비용 함수)
> 우리 모델이 좋은지 안 좋은지 판단하는 식

머신러닝에서는 <code>y = ax + b</code> 이처럼 수식을 작성하지 않고, 다음처럼 작성합니다.

<pre>
y = wx + b

// w는 weight
// b는 bias
</pre>

오차라는 개념이 있습니다. 그래프 상에서 타겟과 직선의 차이를 의미합니다. 직선과 타겟의 차이를 구하는 것이기 때문에, <code>t - y</code>로 구할 수 있으며, 당연히 <code>t</code>는 타겟이고, <code>y</code>는 추정치입니다.

이 오차를 어떻게 구할지 관건이었습니다. 단순히 오차들을 더하는 건 제외시켰습니다. 양수와 음수가 같이 있어 부호 문제가 있기 때문입니다. 그 다음에 오차를 구하기 위해 각각을 제곱하기로 하지만, 오차가 너무 큰, 즉 상황이 너무 안 좋은 케이스의 값이 너무 커지는 일이 발생할 수 있습니다.

그래서 사용하는 것이 평균 제곱 오차(MSE. Mean Sqared Error)입니다. 결론적으로 우리 모델이 좋은지 안 좋은지 판단하기 위해 저희는 많은 로스로 <code>MSE</code>를 사용하고자 하는 것입니다. 로스 함수 사용 시, 독립 변수와 종속 변수를 사용해 구하기 때문에 MSE를 사용하는 거지 꼭 로스 함수 = MSE로 고정된 것은 아닙니다.

다시 돌아와,

<pre>
y = wx + b

Error = t - y 
Error = t - wx + b

loss = MSE(평균 제곱 오차)

// 일반식
loss function = 
</pre>

로스 함수는 포물선의 형태를 가지고 있는데, 계속 말했듯이 오차가 적을수록 좋습니다. 포물선 모양이 오차가 적은, 로스 값이 가장 적을 때가 딱 한 번 있는데, 그 값이 베스트일 것입니다. 그러면 그 값을 어떻게 찾을까요? 랜덤으로 계속 찍으면서 확인하는 수밖에 없습니다. 여기서 미분이 사용됩니다.

포물선에서 저희가 찾는 로스 값이 가장 작은 부분과 맞닿는 부분은 x축과 평행한, 기울기가 0인 상태입니다. 즉 로스 함수를 미분했을 때 값이 0이 나오는 지점이 가장 베스트일 것입니다.

### 반복 학습

독립변수와 종속변수를 가지고, 독립변수를 프로그램에 입력 후(<code>y = wx + b</code>), 예측치와 종속변수를 비교해 상태가 좋으면 끝, 아니면 다시 <code>w</code>와 <code>b</code>를 갱신해(미분) <code>y = wx + b</code> 수식을 통해 예측치를 도출해냅니다. 이런 반복 과정을 반복 학습이라고 합니다.

하지만 데이터는 어마무시하게 많습니다. 수많은 데이터들이 이렇게 루프를 돌며 예측치를 구하고 t와 비교하고 다시 루프를 돌면 속도가 매우 느려질 것입니다. 따라서 속도 개선을 위해 이 부분을 행렬곱 연산으로 해결이 가능합니다.

가령 다음과 같은 데이터가 있다고 가정해 봅시다.

<pre>
x  t
-----
10 9
8  7
5  3
1  1
.  .
.  .
</pre>

x와 t는 각각 4X1의 2차원 행렬입니다. 이를 1X1의 2차원 행렬 w와 행렬곱으로 값을 구할 수 있습니다. 즉 둘을 2차원 매트릭스 데이터로 만들어 프로그램에 입력해 줘야 합니다. 2차원 행렬을 사용하는 이유는 shape이 맞아야 행렬곱이 가능하기 때문입니다.


